{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "fileDay = datetime.date.today().strftime('%Y%m%d')\n",
    "fileYear = datetime.date.today().strftime('%Y')\n",
    "\n",
    "country = []\n",
    "totCase = []\n",
    "\n",
    "nationLink = [] # www.worldometers.info/coronavirus/ + 'country/name'\n",
    "\n",
    "def scrapingWorldometers():\n",
    "    url = \"https://www.worldometers.info/coronavirus/\"\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    colList = []\n",
    "    dateList = []\n",
    "    caseDataList = []\n",
    "    deathDataList = []\n",
    "    df = None\n",
    "    \n",
    "    #if yda:\n",
    "        #table = soup.select_one('table#main_table_countries_yesterday')\n",
    "    #else:    \n",
    "    table = soup.select_one('table#main_table_countries_today')\n",
    "    #pprint(table)\n",
    "\n",
    "    columns = table.select('tr')\n",
    "    isCol = True\n",
    "\n",
    "    for col in columns:\n",
    "        if isCol:\n",
    "            cols = col.select('th')\n",
    "            for c in cols:\n",
    "                colList.append(c.text)\n",
    "            isCol = False\n",
    "        else:\n",
    "            rows = col.select('td') # '#' [0] column was added, so that index changed in 5. 15.\n",
    "            cases = int(rows[2].text.strip().replace(',',''))\n",
    "            if (cases >= 1000) and rows[1].a: \n",
    "                country.append(rows[1].text.strip())\n",
    "                nationLink.append(rows[1].a[\"href\"])\n",
    "                totCase.append(cases)\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "    # Réunion, Curaçao => Reunion, Curacao\n",
    "    if \"Réunion\" in country:\n",
    "        idx = country.index(\"Réunion\")\n",
    "        country[idx] = \"Reunion\"\n",
    "    \n",
    "    if \"Curaçao\" in country:\n",
    "        idx = country.index(\"Curaçao\")\n",
    "        country[idx] = \"Curacao\"\n",
    "\n",
    "            \n",
    "    for link in nationLink:\n",
    "        html = requests.get(url + link).text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        jsList = soup.find_all('script', attrs={'type' : \"text/javascript\"})\n",
    "        for js in jsList:\n",
    "            if js.text.find(\"Highcharts\") != -1:\n",
    "                if js.text.find(\"'coronavirus-cases-linear'\") != -1:\n",
    "                    caseScript = js.text\n",
    "                    frontCut = caseScript[caseScript.find(\"categories:\"):]\n",
    "                    caseDaysStartIdx = frontCut.find(\"[\") + 1 # start from inside of []\n",
    "                    caseDaysEndIdx = frontCut.find(\"]\")\n",
    "                    caseDaysList = frontCut[caseDaysStartIdx:caseDaysEndIdx].split(\",\")\n",
    "                    \n",
    "                    startDate = datetime.datetime.strptime(caseDaysList[0].strip('\"') + ' 2020', \"%b %d %Y\")\n",
    "                    endDate = datetime.datetime.strptime(caseDaysList[-1].strip('\"') + ' ' + fileYear, \"%b %d %Y\")\n",
    "                    dateList = pd.date_range(startDate, endDate)\n",
    "                    \n",
    "                    frontCut = frontCut[frontCut.find(\"data:\"):]\n",
    "                    caseDataStartIdx = frontCut.find(\"[\") + 1 # start from inside of []\n",
    "                    caseDataEndIdx = frontCut.find(\"]\")\n",
    "                    caseDataList = frontCut[caseDataStartIdx:caseDataEndIdx].split(\",\")\n",
    "                    \n",
    "                elif js.text.find(\"coronavirus-deaths-linear\") != -1:\n",
    "                    deathScript = js.text\n",
    "                    frontCut = deathScript[deathScript.find(\"data:\"):]\n",
    "                    deathDataStartIdx = frontCut.find(\"[\") + 1 # start from inside of []\n",
    "                    deathDataEndIdx = frontCut.find(\"]\")\n",
    "                    deathDataList = frontCut[deathDataStartIdx:deathDataEndIdx].split(\",\")\n",
    "        \n",
    "        nationDict = {\"Country\": country[nationLink.index(link)], \"Date\":dateList, \"TotalCases\":caseDataList, \"TotalDeaths\":deathDataList}\n",
    "        dfByNation = pd.DataFrame(nationDict)\n",
    "        df = pd.concat([df, dfByNation])\n",
    "        \n",
    "    df[\"Date\"] = df[\"Date\"].astype(str) # datetime64[ns] -> str\n",
    "    df = df.set_index([\"Country\", \"Date\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toCSV(df):\n",
    "    csvFile = './covidDataset/' + fileDay + 'CoronaWorld.csv' # set directory properly\n",
    "    df.to_csv(csvFile)\n",
    "    print(fileDay, \"today csv complete\")\n",
    "    \n",
    "def toJSON(df, orient='split'):\n",
    "    jsonFile = './covidDataset/' + fileDay + 'CoronaWorld.json'\n",
    "    df.to_json(jsonFile, orient)\n",
    "    print(fileDay, \"today json complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   TotalCases TotalDeaths\n",
      "Country Date                             \n",
      "USA     2020-02-15         15           0\n",
      "        2020-02-16         15           0\n",
      "        2020-02-17         15           0\n",
      "        2020-02-18         15           0\n",
      "        2020-02-19         15           0\n",
      "...                       ...         ...\n",
      "China   2020-05-10      82901        4633\n",
      "        2020-05-11      82918        4633\n",
      "        2020-05-12      82919        4633\n",
      "        2020-05-13      82926        4633\n",
      "        2020-05-14      82929        4633\n",
      "\n",
      "[8934 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "covidDataFrame = scrapingWorldometers()\n",
    "print(covidDataFrame) # only china start from 2020-01-22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20200515 today csv complete\n",
      "20200515 today json complete\n"
     ]
    }
   ],
   "source": [
    "toCSV(covidDataFrame)\n",
    "toJSON(covidDataFrame)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
